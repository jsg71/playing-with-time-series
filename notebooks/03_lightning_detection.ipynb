{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightning Detection with NCD\n",
    "This notebook demonstrates compression-based lightning detection using **Normalised Compression Distance** (NCD). We also compare a simple amplitude-threshold baseline."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T13:35:39.610485Z",
     "start_time": "2025-06-22T13:35:39.587263Z"
    }
   },
   "source": [
    "import json, numpy as np, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from pandas import Series\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from leela_ml.datamodules_npy import StrikeDataset\n",
    "from leela_ml.ncd import ncd_adjacent, ncd_first\n"
   ],
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ncd_first' from 'leela_ml.ncd' (/Users/johngoodacre/leela-ml/leela_ml/ncd.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[44]\u001B[39m\u001B[32m, line 8\u001B[39m\n\u001B[32m      6\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mseaborn\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msns\u001B[39;00m\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mleela_ml\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdatamodules_npy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m StrikeDataset\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mleela_ml\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mncd\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ncd_adjacent, ncd_first\n",
      "\u001B[31mImportError\u001B[39m: cannot import name 'ncd_first' from 'leela_ml.ncd' (/Users/johngoodacre/leela-ml/leela_ml/ncd.py)"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from leela_ml.signal_sim.simulator import simulate\n",
    "out_prefix = Path('data/demo')\n",
    "simulate(1, str(out_prefix), seed=0)\n",
    "npy = 'data/demo_LON.npy'\n",
    "meta = 'data/demo_meta.json'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = StrikeDataset(npy, meta, chunk_size=512, overlap=0.9)\n",
    "win = ds._windows.astype(np.float32, copy=False)\n",
    "lab = ds.labels.astype(bool)\n",
    "fs = ds.fs; hop = ds.hop\n",
    "print(\"windows\", ds.n_win, \"positives\", int(lab.sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. NCD computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = ncd_adjacent(win, per_win_norm=True)\n",
    "win_len = max(1, int(0.01 * fs / hop))\n",
    "thr = Series(err).rolling(win_len, center=True, min_periods=1).median() + 6*Series(err).rolling(win_len, center=True, min_periods=1).apply(lambda v: np.median(np.abs(v-np.median(v))), raw=True)\n",
    "mask = err > thr.values\n",
    "tn, fp, fn, tp = confusion_matrix(lab, mask).ravel()\n",
    "P,R,F,_ = precision_recall_fscore_support(lab, mask, average='binary')\n",
    "metrics_ncd = dict(P=float(P), R=float(R), F1=float(F), TP=int(tp), FP=int(fp), FN=int(fn), TN=int(tn))\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "err_first = ncd_first(win, baseline_idx=0, per_win_norm=True)\n",
    "thr_first = Series(err_first).rolling(win_len, center=True, min_periods=1).median() + 6*Series(err_first).rolling(win_len, center=True, min_periods=1).apply(lambda v: np.median(np.abs(v-np.median(v))), raw=True)\n",
    "mask_first = err_first > thr_first.values\n",
    "tn, fp, fn, tp = confusion_matrix(lab, mask_first).ravel()\n",
    "P1,R1,F1,_ = precision_recall_fscore_support(lab, mask_first, average='binary')\n",
    "metrics_first = dict(P=float(P1), R=float(R1), F1=float(F1), TP=int(tp), FP=int(fp), FN=int(fn), TN=int(tn))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Simple amplitude threshold baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp = np.sqrt((win**2).mean(axis=1))\n",
    "thr_amp = Series(amp).rolling(win_len, center=True, min_periods=1).median() + 6*Series(amp).rolling(win_len, center=True, min_periods=1).apply(lambda v: np.median(np.abs(v-np.median(v))), raw=True)\n",
    "mask_amp = amp > thr_amp.values\n",
    "tn, fp, fn, tp = confusion_matrix(lab, mask_amp).ravel()\n",
    "Pa,Ra,Fa,_ = precision_recall_fscore_support(lab, mask_amp, average='binary')\n",
    "metrics_amp = dict(P=float(Pa), R=float(Ra), F1=float(Fa), TP=int(tp), FP=int(fp), FN=int(fn), TN=int(tn))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NCD metrics', metrics_ncd)\n",
    "print('Amplitude metrics', metrics_amp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot NCD and baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,4))\n",
    "plt.plot(err, label='NCD', lw=0.4)\n",
    "plt.plot(thr, '--', label='threshold', lw=0.8)\n",
    "plt.legend(); plt.title('NCD curve')\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T14:01:26.278714Z",
     "start_time": "2025-06-22T14:01:20.886351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np, zlib, pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import IsolationForest   # kept for comparison\n",
    "from scipy.signal import welch\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# ─── 1. simulate 60 s @100 kHz with 20 flashes ─────────────────────────────\n",
    "fs, dur, n_flashes = 100_000, 60, 20\n",
    "N = fs*dur\n",
    "flash_len = int(0.003*fs)                # 3 ms\n",
    "np.random.seed(42)\n",
    "signal = 0.2*np.random.randn(N).astype(np.float32)\n",
    "labels = np.zeros(N, bool)\n",
    "starts = np.sort(np.random.choice(N-flash_len, n_flashes, replace=False))\n",
    "for idx in starts:\n",
    "    t = np.arange(flash_len)/fs\n",
    "    signal[idx:idx+flash_len] += np.exp(-t/0.001)*np.cos(2*np.pi*4e3*t)\n",
    "    labels[idx:idx+flash_len] = True\n",
    "\n",
    "# ─── 2. windowing ───────────────────────────────────────────────────────────\n",
    "win, hop = 1024, 256                     # 75 % overlap\n",
    "n_win = (N-win)//hop + 1\n",
    "win_lab = np.array([labels[i*hop:i*hop+win].any() for i in range(n_win)])\n",
    "\n",
    "# ─── 3. STA / LTA ratio per window ──────────────────────────────────────────\n",
    "abs_sig = np.abs(signal)\n",
    "sta = np.convolve(abs_sig, np.ones(int(0.002*fs))/int(0.002*fs), mode='same')\n",
    "lta = np.convolve(abs_sig, np.ones(int(0.05*fs))/int(0.05*fs), mode='same') + 1e-6\n",
    "sta_lta = sta/lta\n",
    "# pick, for each window, the max STA/LTA inside that window\n",
    "ratio_win = np.array([sta_lta[i*hop:(i*hop+win)].max() for i in range(n_win)])\n",
    "\n",
    "# ─── 4. robust threshold (k·σ above mean) ───────────────────────────────────\n",
    "k = 6                                 # tuned once; still unsupervised\n",
    "thr = ratio_win.mean() + k*ratio_win.std()\n",
    "pred_win = ratio_win > thr               # boolean per window\n",
    "\n",
    "# ─── 5. window‑level metrics ───────────────────────────────────────────────\n",
    "P,R,F,_ = precision_recall_fscore_support(win_lab, pred_win, average='binary')\n",
    "tn,fp,fn,tp = confusion_matrix(win_lab, pred_win).ravel()\n",
    "window_metrics = dict(P=float(P), R=float(R), F1=float(F),\n",
    "                      TP=int(tp), FP=int(fp), FN=int(fn), TN=int(tn))\n",
    "# → {'P': 0.92, 'R': 0.92, 'F1': 0.92,  TP=93, FP=8, FN=8, TN=23 325}\n",
    "\n",
    "# ─── 6. event‑level scoring (merge consecutive detections) ──────────────────\n",
    "def windows_to_events(flags):\n",
    "    events=[]; cur=None\n",
    "    for i,f in enumerate(flags):\n",
    "        if f and cur is None: cur=[i,i]\n",
    "        elif f: cur[1]=i\n",
    "        elif cur is not None: events.append(tuple(cur)); cur=None\n",
    "    if cur is not None: events.append(tuple(cur))\n",
    "    return events\n",
    "\n",
    "det_evt  = windows_to_events(pred_win)\n",
    "true_evt = [(max(0,(idx-hop)//hop), min(n_win-1,(idx+flash_len)//hop))\n",
    "            for idx in starts]\n",
    "\n",
    "tp_e=sum(any(not(de<gs or ds>ge) for ds,de in det_evt) for gs,ge in true_evt)\n",
    "fn_e=len(true_evt)-tp_e\n",
    "fp_e=sum(not any(not(de<gs or ds>ge) for gs,ge in true_evt) for ds,de in det_evt)\n",
    "\n",
    "event_metrics = dict(P=tp_e/(tp_e+fp_e),\n",
    "                     R=tp_e/(tp_e+fn_e),\n",
    "                     F1=2*tp_e/max(1,tp_e*2+fp_e+fn_e),\n",
    "                     TP=tp_e, FP=fp_e, FN=fn_e)\n",
    "# → {'P': 0.91, 'R': 1.00, 'F1': 0.95, TP=20, FP=2, FN=0}\n"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T14:01:26.297536Z",
     "start_time": "2025-06-22T14:01:26.295063Z"
    }
   },
   "cell_type": "code",
   "source": "event_metrics",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P': 0.9090909090909091,\n",
       " 'R': 1.0,\n",
       " 'F1': 0.9523809523809523,\n",
       " 'TP': 20,\n",
       " 'FP': 2,\n",
       " 'FN': 0}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
