{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ce1ad38",
   "metadata": {},
   "source": [
    "# 03 Extensive EDA – Single-Station Lightning Waveforms ⚡\n",
    "\n",
    "This notebook demonstrates an in-depth exploratory data analysis (EDA) for a single station. It mirrors the style of `01_eda.ipynb` and `02_eda.ipynb` but dives much deeper with many statistics and signal-processing visualisations.  It assumes you have generated synthetic lightning data using `scripts/sim_make.py` or obtained real recordings.\n",
    "\n",
    "We will load the waveform for one station, inspect noise characteristics, visualise several events, and experiment with classic time-series techniques to pinpoint lightning occurrences.  Later we will attempt a simple denoising approach and evaluate detection accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5e6d9f",
   "metadata": {},
   "source": [
    "## 0. Imports and file paths\n",
    "```python\n",
    "import numpy as np\n",
    "import json, pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as sig\n",
    "```\n",
    "\n",
    "Adjust the paths below to point at your waveform (`.npy`) and its accompanying meta file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7299a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ╔══════════════════════════════════════════════════════════╗\n",
    "# ║ 0. File paths and loading helpers                       ║\n",
    "# ╚══════════════════════════════════════════════════════════╝\n",
    "import numpy as np, json, pathlib, scipy.signal as sig, matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\".\")\n",
    "from leela_ml.signal_sim import simulator\n",
    "\n",
    "root = pathlib.Path(\"../data\")\n",
    "wave_f = root / \"demo_LON.npy\"\n",
    "meta_f = root / \"demo_meta.json\"\n",
    "if not wave_f.exists():\n",
    "    simulator.simulate(1, str(root / \"demo\"))\n",
    "wave = np.load(wave_f, mmap_mode=\"r\")\n",
    "meta = json.load(open(meta_f))\n",
    "fs = meta[\"fs\"]\n",
    "events = meta[\"events\"]\n",
    "print(\"Samples:\", wave.shape[0], \"Fs=\", fs)\n",
    "print(\"Total events:\", len(events))\n",
    "print(\"First event:\", events[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c020ba",
   "metadata": {},
   "source": [
    "## 1. First-look visualisation\n",
    "Plot the first few seconds of the waveform to see noise and a sample lightning burst.  We also compute a short-time Fourier transform (spectrogram) to examine frequency content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5ecac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ╔══════════════════════════════════════════════════════════╗\n",
    "# ║ 1. First-second waveform & spectrogram                  ║\n",
    "# ╚══════════════════════════════════════════════════════════╝\n",
    "sec = wave[:fs]\n",
    "t = np.arange(sec.size) / fs\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 4), sharex=True)\n",
    "ax[0].plot(t, sec)\n",
    "ax[0].set_ylabel(\"E-field (arb.)\")\n",
    "ax[0].set_title(\"First second\")\n",
    "ax[1].specgram(sec, Fs=fs, NFFT=2048, noverlap=1024, cmap=\"viridis\")\n",
    "ax[1].set_xlabel(\"Time (s)\")\n",
    "ax[1].set_ylabel(\"Frequency (Hz)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b88cf91",
   "metadata": {},
   "source": [
    "## 2. Noise statistics\n",
    "We quantify baseline noise to help choose detection thresholds.  Basic statistics include mean, standard deviation, power spectral density and the amplitude envelope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6674e6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ╔══════════════════════════════════════════════════════════╗\n",
    "# ║ 2. Noise characteristics                                 ║\n",
    "# ╚══════════════════════════════════════════════════════════╝\n",
    "noise_seg = wave[: fs * 5]\n",
    "mean = float(noise_seg.mean())\n",
    "std = float(noise_seg.std())\n",
    "f, Pxx = sig.welch(noise_seg, fs, nperseg=4096)\n",
    "print(\"Mean\", mean, \"Std\", std)\n",
    "plt.semilogy(f, Pxx)\n",
    "plt.xlabel(\"Hz\")\n",
    "plt.ylabel(\"PSD\")\n",
    "plt.show()\n",
    "rect = np.abs(noise_seg)\n",
    "b, a = sig.butter(2, 500 / (fs / 2))\n",
    "env = sig.filtfilt(b, a, rect)\n",
    "plt.plot(np.arange(env.size) / fs, env)\n",
    "plt.title(\"Noise envelope\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261e365d",
   "metadata": {},
   "source": [
    "## 3. Explore lightning events\n",
    "Loop over a few labelled events and display their waveform snippets with annotations such as predicted start time, duration and approximate peak frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569e7855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ╔══════════════════════════════════════════════════════════╗\n",
    "# ║ 3. Inspect several labelled events                       ║\n",
    "# ╚══════════════════════════════════════════════════════════╝\n",
    "for ev in events[:3]:\n",
    "    i0 = int(ev[\"t\"] * fs)\n",
    "    sl = slice(i0 - int(0.01 * fs), i0 + int(0.05 * fs))\n",
    "    snip = wave[sl]\n",
    "    t_snip = (np.arange(snip.size) / fs) - 0.01\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.plot(t_snip * 1000, snip)\n",
    "    plt.axvline(0, color=\"r\", ls=\"--\", label=\"event t\")\n",
    "    plt.xlabel(\"ms\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.title(f\"Event at t={ev['t']:.3f}s, amp={ev['amp']:.2f}\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195f698f",
   "metadata": {},
   "source": [
    "## 4. Rolling statistics & envelope\n",
    "A moving window view helps us detect bursts. We compute rolling mean, rolling std, and a smooth envelope via Hilbert transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc38ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ╔══════════════════════════════════════════════════════════╗\n",
    "# ║ 4. Rolling stats and envelope                            ║\n",
    "# ╚══════════════════════════════════════════════════════════╝\n",
    "window_ms = 1\n",
    "win = int(window_ms * 1e-3 * fs)\n",
    "roll_mean = np.convolve(wave, np.ones(win) / win, mode=\"same\")\n",
    "roll_std = np.sqrt(\n",
    "    np.convolve((wave - roll_mean) ** 2, np.ones(win) / win, mode=\"same\")\n",
    ")\n",
    "envelope = np.abs(sig.hilbert(wave))\n",
    "plt.plot(envelope[: fs * 2])\n",
    "plt.title(\"Envelope – first two seconds\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffd34a5",
   "metadata": {},
   "source": [
    "## 5. Simple band-pass filter (denoising)\n",
    "We design a Butterworth band-pass filter to suppress low-frequency drift and high-frequency noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7074fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ╔══════════════════════════════════════════════════════════╗\n",
    "# ║ 5. Band-pass filter                                       ║\n",
    "# ╚══════════════════════════════════════════════════════════╝\n",
    "low, high = 3000, 9000\n",
    "b, a = sig.butter(4, [low / (fs / 2), high / (fs / 2)], btype=\"band\")\n",
    "wave_filt = sig.filtfilt(b, a, wave)\n",
    "plt.plot(wave[:fs], label=\"orig\")\n",
    "plt.plot(wave_filt[:fs], label=\"filt\", alpha=0.7)\n",
    "plt.legend()\n",
    "plt.title(\"Band-pass filtered\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd02b707",
   "metadata": {},
   "source": [
    "## 6. Burst detection via envelope threshold\n",
    "Using the filtered waveform we compute the envelope and apply a threshold based on noise statistics. Detections are compared against ground truth event times for a basic precision/recall estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebb2715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ╔══════════════════════════════════════════════════════════╗\n",
    "# ║ 6. Envelope threshold detector                           ║\n",
    "# ╚══════════════════════════════════════════════════════════╝\n",
    "env_f = np.abs(sig.hilbert(wave_filt))\n",
    "noise_level = np.median(env_f) + 6 * np.median(np.abs(env_f - np.median(env_f)))\n",
    "detections = env_f > noise_level\n",
    "det_times = np.where(np.diff(detections.astype(int)) == 1)[0] / fs\n",
    "print(\"Detected events:\", len(det_times))\n",
    "true_times = np.array([ev[\"t\"] for ev in events])\n",
    "tol = 0.005  # seconds tolerance when matching\n",
    "# match detections to true events\n",
    "tp_det = np.sum(np.any(np.abs(det_times[:, None] - true_times) <= tol, axis=1))\n",
    "tp_evt = np.sum(np.any(np.abs(true_times[:, None] - det_times) <= tol, axis=1))\n",
    "fp = len(det_times) - tp_det\n",
    "fn = len(true_times) - tp_evt\n",
    "print(f\"TP_events={tp_evt}, FP={fp}, FN={fn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a84ea06",
   "metadata": {},
   "source": [
    "# ╔══════════════════════════════════════════════════════════╗\n",
    "# ║ 6.1 Detection metrics                                     ║\n",
    "# ╚══════════════════════════════════════════════════════════╝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f106034",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = tp_evt / (tp_evt + fp) if tp_evt + fp else 0\n",
    "recall = tp_evt / (tp_evt + fn) if tp_evt + fn else 0\n",
    "f1 = 2 * precision * recall / (precision + recall) if precision + recall else 0\n",
    "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1593cb",
   "metadata": {},
   "source": [
    "## 7. Extract clean waveforms\n",
    "Extract short snippets around each detected event for further analysis or model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9abdfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ╔══════════════════════════════════════════════════════════╗\n",
    "# ║ 7. Snippet extraction                                    ║\n",
    "# ╚══════════════════════════════════════════════════════════╝\n",
    "snippets = []\n",
    "for t0 in det_times:\n",
    "    i0 = int((t0 - 0.005) * fs)\n",
    "    sl = slice(max(i0, 0), i0 + int(0.04 * fs))\n",
    "    snippets.append(wave_filt[sl])\n",
    "\n",
    "plt.figure(figsize=(9, 3))\n",
    "for i, snip in enumerate(snippets[:3]):\n",
    "    plt.plot(np.arange(len(snip)) / fs * 1000, snip + i * 0.2, label=f\"ev {i}\")\n",
    "plt.xlabel(\"ms\")\n",
    "plt.title(\"First detections\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-filter",
   "metadata": {},
   "source": [
    "## 8. Matched filter detection\n",
    "A simple matched filter slides an idealised waveform template over the recording and correlates it with the signal. Peaks in the correlation indicate likely lightning events.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-filter-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ╔══════════════════════════════════════════════════════════╗\n",
    "# ║ 8. Matched filter detection                               ║\n",
    "# ╚══════════════════════════════════════════════════════════╝\n",
    "template = snippets[0]  # crude template using first snippet\n",
    "template = (template - template.mean()) / template.std()\n",
    "xcorr = sig.fftconvolve(wave_filt, template[::-1], mode=\"same\")\n",
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(xcorr)\n",
    "plt.title(\"Matched filter response\")\n",
    "plt.show()\n",
    "peak_idx = np.argsort(xcorr)[-len(events) :]\n",
    "peak_times = np.sort(peak_idx) / fs\n",
    "print(\"Top correlation peak times:\", peak_times[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amp-dist",
   "metadata": {},
   "source": [
    "## 9. Event amplitude distribution\n",
    "We examine the distribution of true event amplitudes and compare with the amplitudes measured after filtering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amp-hist-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ╔══════════════════════════════════════════════════════════╗\n",
    "# ║ 9. Amplitude histograms                                   ║\n",
    "# ╚══════════════════════════════════════════════════════════╝\n",
    "true_amps = np.array([ev[\"amp\"] for ev in events])\n",
    "measured_amps = [snip.max() - snip.min() for snip in snippets]\n",
    "plt.hist(true_amps, bins=20, alpha=0.6, label=\"true\")\n",
    "plt.hist(measured_amps, bins=20, alpha=0.6, label=\"measured\")\n",
    "plt.legend()\n",
    "plt.title(\"Event amplitude distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stft-events",
   "metadata": {},
   "source": [
    "## 9.1 STFT around events\n",
    "We view spectrograms of short snippets around each labelled event to analyse frequency content evolution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stft-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ╔══════════════════════════════════════════════════════════╗\n",
    "# ║ 9.1 STFT per event                                        ║\n",
    "# ╚══════════════════════════════════════════════════════════╝\n",
    "win = sig.windows.hann(256)\n",
    "for ev in events[:3]:\n",
    "    i0 = int(ev[\"t\"] * fs)\n",
    "    seg = wave[i0 - int(0.01 * fs) : i0 + int(0.02 * fs)]\n",
    "    f, t, S = sig.spectrogram(seg, fs=fs, window=win, nperseg=256, noverlap=128)\n",
    "    plt.pcolormesh(t - 0.01, f, 20 * np.log10(S + 1e-6), shading=\"auto\")\n",
    "    plt.title(f'STFT around event at {ev[\"t\"]:.3f}s')\n",
    "    plt.ylabel(\"Hz\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wavelet",
   "metadata": {},
   "source": [
    "## 10. Wavelet time-frequency view\n",
    "Wavelet transforms provide a clearer time-frequency picture for transient bursts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wavelet-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ╔══════════════════════════════════════════════════════════╗\n",
    "# ║ 10. Wavelet transform                                     ║\n",
    "# ╚══════════════════════════════════════════════════════════╝\n",
    "import pywt\n",
    "\n",
    "scales = np.arange(1, 128)\n",
    "coef, freqs = pywt.cwt(wave[: fs * 2], scales, \"mexh\", sampling_period=1 / fs)\n",
    "plt.imshow(\n",
    "    np.abs(coef), extent=[0, 2, freqs[-1], freqs[0]], aspect=\"auto\", cmap=\"turbo\"\n",
    ")\n",
    "plt.ylabel(\"Frequency (Hz)\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.title(\"CWT of first 2s\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crosscorr",
   "metadata": {},
   "source": [
    "## 10.1 Cross-correlation check\n",
    "Cross-correlating snippets verifies alignment between predicted and actual events. High peaks indicate consistent timing across events.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crosscorr-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ╔══════════════════════════════════════════════════════════╗\n",
    "# ║ 10.1 Cross-correlation                                     ║\n",
    "# ╚══════════════════════════════════════════════════════════╝\n",
    "ref = snippets[0]\n",
    "for i, s in enumerate(snippets[1:4], start=1):\n",
    "    corr = sig.correlate(s, ref, mode=\"full\")\n",
    "    lags = np.arange(-len(s) + 1, len(ref)) / fs\n",
    "    plt.figure(figsize=(6, 2))\n",
    "    plt.plot(lags * 1000, corr)\n",
    "    plt.title(f\"Corr snippet {i} vs 0\")\n",
    "    plt.xlabel(\"lag ms\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. NCD anomaly detection\n",
    "We apply the Normalised Compression Distance (NCD) to consecutive windows.\n",
    "Spikes in NCD highlight segments that differ from their immediate predecessor.\n",
    "The simple approach below computes a rolling threshold and compares detections\n",
    "against our labelled lightning events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ╔══════════════════════════════════════════════════════════╗\n",
    "# ║ 11. NCD-based detection                                   ║\n",
    "# ╚══════════════════════════════════════════════════════════╝\n",
    "from pandas import Series\n",
    "from leela_ml.datamodules_npy import StrikeDataset\n",
    "from leela_ml.models.ncd import ncd_adjacent\n",
    "import inspect\n",
    "\n",
    "chunk = 512\n",
    "overlap = 0.9\n",
    "ds = StrikeDataset(wave_f, meta_f, chunk_size=chunk, overlap=overlap)\n",
    "sig = inspect.signature(ncd_adjacent)\n",
    "if \"per_win_norm\" in sig.parameters:\n",
    "    ncd_vec = ncd_adjacent(\n",
    "        ds._windows.astype(np.float32, copy=False), per_win_norm=True\n",
    "    )\n",
    "else:\n",
    "    ncd_vec = ncd_adjacent(ds._windows.astype(np.float32, copy=False), per_win_nor=True)\n",
    "win_len = max(1, int(0.01 * fs / ds.hop))\n",
    "roll = Series(ncd_vec).rolling(win_len, center=True, min_periods=1)\n",
    "thr = roll.median() + 2 * roll.apply(\n",
    "    lambda v: np.median(np.abs(v - np.median(v))), raw=True\n",
    ")\n",
    "mask = ncd_vec > thr\n",
    "ncd_times = np.where(np.diff(mask.astype(int)) == 1)[0] * ds.hop / fs\n",
    "tp_det = np.sum(np.any(np.abs(ncd_times[:, None] - true_times) <= tol, axis=1))\n",
    "tp_evt = np.sum(np.any(np.abs(true_times[:, None] - ncd_times) <= tol, axis=1))\n",
    "fp = len(ncd_times) - tp_det\n",
    "fn = len(true_times) - tp_evt\n",
    "precision = tp_evt / (tp_evt + fp) if tp_evt + fp else 0\n",
    "recall = tp_evt / (tp_evt + fn) if tp_evt + fn else 0\n",
    "f1 = 2 * precision * recall / (precision + recall) if precision + recall else 0\n",
    "noise_mean = ncd_vec[~mask].mean()\n",
    "burst_mean = ncd_vec[mask].mean() if mask.any() else float(\"nan\")\n",
    "print(f\"NCD P={precision:.2f} R={recall:.2f} F1={f1:.2f}\")\n",
    "print(f\"NCD mean noise={noise_mean:.3f}  burst={burst_mean:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Matched-filter detection\n",
    "Cross-correlate the waveform with a template from the first event and apply a rolling threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ╔══ Matched-filter detection ══╗\n",
    "template = wave_filt[int(true_times[0] * fs) : int(true_times[0] * fs) + chunk]\n",
    "xcorr = sig.fftconvolve(wave_filt, template[::-1], mode=\"same\")\n",
    "roll = Series(xcorr).rolling(win_len, center=True, min_periods=1)\n",
    "thr = roll.median() + 4 * roll.std()\n",
    "mask = xcorr > thr\n",
    "det_times = np.where(np.diff(mask.astype(int)) == 1)[0] / fs\n",
    "tp_det = np.sum(np.any(np.abs(det_times[:, None] - true_times) <= tol, axis=1))\n",
    "tp_evt = np.sum(np.any(np.abs(true_times[:, None] - det_times) <= tol, axis=1))\n",
    "fp = len(det_times) - tp_det\n",
    "fn = len(true_times) - tp_evt\n",
    "precision = tp_evt / (tp_evt + fp) if tp_evt + fp else 0\n",
    "recall = tp_evt / (tp_evt + fn) if tp_evt + fn else 0\n",
    "f1 = 2 * precision * recall / (precision + recall) if precision + recall else 0\n",
    "print(f\"Matched P={precision:.2f} R={recall:.2f} F1={f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-more",
   "metadata": {},
   "source": [
    "## 11. Further work\n",
    "These analyses illustrate many avenues for lightning signal exploration. Extending to cross-station coherence or machine learning will build upon this foundation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309cfea4",
   "metadata": {},
   "source": [
    "## 8. Conclusions\n",
    "We showcased a wide array of EDA techniques on a single-station recording: noise analysis, spectral content, rolling statistics, simple denoising and envelope-based detection.  These provide insight into lightning signal properties and form a baseline for future modelling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
